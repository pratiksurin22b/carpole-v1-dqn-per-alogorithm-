{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Total Reward: 16.0\n",
      "Episode 1, Total Reward: 18.0\n",
      "Episode 2, Total Reward: 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pratik\\AppData\\Local\\Temp\\ipykernel_19536\\1343452155.py:135: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  states = torch.FloatTensor(states)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3, Total Reward: 46.0\n",
      "Episode 4, Total Reward: 12.0\n",
      "Episode 5, Total Reward: 18.0\n",
      "Episode 6, Total Reward: 23.0\n",
      "Episode 7, Total Reward: 18.0\n",
      "Episode 8, Total Reward: 21.0\n",
      "Episode 9, Total Reward: 61.0\n",
      "Episode 10, Total Reward: 13.0\n",
      "Episode 11, Total Reward: 25.0\n",
      "Episode 12, Total Reward: 18.0\n",
      "Episode 13, Total Reward: 16.0\n",
      "Episode 14, Total Reward: 18.0\n",
      "Episode 15, Total Reward: 34.0\n",
      "Episode 16, Total Reward: 30.0\n",
      "Episode 17, Total Reward: 27.0\n",
      "Episode 18, Total Reward: 21.0\n",
      "Episode 19, Total Reward: 22.0\n",
      "Episode 20, Total Reward: 13.0\n",
      "Episode 21, Total Reward: 18.0\n",
      "Episode 22, Total Reward: 47.0\n",
      "Episode 23, Total Reward: 25.0\n",
      "Episode 24, Total Reward: 19.0\n",
      "Episode 25, Total Reward: 31.0\n",
      "Episode 26, Total Reward: 25.0\n",
      "Episode 27, Total Reward: 26.0\n",
      "Episode 28, Total Reward: 14.0\n",
      "Episode 29, Total Reward: 37.0\n",
      "Episode 30, Total Reward: 27.0\n",
      "Episode 31, Total Reward: 37.0\n",
      "Episode 32, Total Reward: 38.0\n",
      "Episode 33, Total Reward: 32.0\n",
      "Episode 34, Total Reward: 60.0\n",
      "Episode 35, Total Reward: 25.0\n",
      "Episode 36, Total Reward: 45.0\n",
      "Episode 37, Total Reward: 43.0\n",
      "Episode 38, Total Reward: 18.0\n",
      "Episode 39, Total Reward: 58.0\n",
      "Episode 40, Total Reward: 18.0\n",
      "Episode 41, Total Reward: 85.0\n",
      "Episode 42, Total Reward: 13.0\n",
      "Episode 43, Total Reward: 27.0\n",
      "Episode 44, Total Reward: 15.0\n",
      "Episode 45, Total Reward: 34.0\n",
      "Episode 46, Total Reward: 36.0\n",
      "Episode 47, Total Reward: 28.0\n",
      "Episode 48, Total Reward: 26.0\n",
      "Episode 49, Total Reward: 26.0\n",
      "Episode 50, Total Reward: 25.0\n",
      "Episode 51, Total Reward: 57.0\n",
      "Episode 52, Total Reward: 27.0\n",
      "Episode 53, Total Reward: 32.0\n",
      "Episode 54, Total Reward: 52.0\n",
      "Episode 55, Total Reward: 31.0\n",
      "Episode 56, Total Reward: 83.0\n",
      "Episode 57, Total Reward: 31.0\n",
      "Episode 58, Total Reward: 48.0\n",
      "Episode 59, Total Reward: 33.0\n",
      "Episode 60, Total Reward: 51.0\n",
      "Episode 61, Total Reward: 129.0\n",
      "Episode 62, Total Reward: 20.0\n",
      "Episode 63, Total Reward: 58.0\n",
      "Episode 64, Total Reward: 56.0\n",
      "Episode 65, Total Reward: 51.0\n",
      "Episode 66, Total Reward: 36.0\n",
      "Episode 67, Total Reward: 33.0\n",
      "Episode 68, Total Reward: 37.0\n",
      "Episode 69, Total Reward: 18.0\n",
      "Episode 70, Total Reward: 35.0\n",
      "Episode 71, Total Reward: 109.0\n",
      "Episode 72, Total Reward: 60.0\n",
      "Episode 73, Total Reward: 19.0\n",
      "Episode 74, Total Reward: 13.0\n",
      "Episode 75, Total Reward: 67.0\n",
      "Episode 76, Total Reward: 102.0\n",
      "Episode 77, Total Reward: 18.0\n",
      "Episode 78, Total Reward: 33.0\n",
      "Episode 79, Total Reward: 41.0\n",
      "Episode 80, Total Reward: 17.0\n",
      "Episode 81, Total Reward: 64.0\n",
      "Episode 82, Total Reward: 22.0\n",
      "Episode 83, Total Reward: 53.0\n",
      "Episode 84, Total Reward: 14.0\n",
      "Episode 85, Total Reward: 22.0\n",
      "Episode 86, Total Reward: 61.0\n",
      "Episode 87, Total Reward: 20.0\n",
      "Episode 88, Total Reward: 158.0\n",
      "Episode 89, Total Reward: 67.0\n",
      "Episode 90, Total Reward: 168.0\n",
      "Episode 91, Total Reward: 99.0\n",
      "Episode 92, Total Reward: 46.0\n",
      "Episode 93, Total Reward: 138.0\n",
      "Episode 94, Total Reward: 127.0\n",
      "Episode 95, Total Reward: 86.0\n",
      "Episode 96, Total Reward: 38.0\n",
      "Episode 97, Total Reward: 113.0\n",
      "Episode 98, Total Reward: 36.0\n",
      "Episode 99, Total Reward: 78.0\n",
      "Episode 100, Total Reward: 25.0\n",
      "Episode 101, Total Reward: 12.0\n",
      "Episode 102, Total Reward: 79.0\n",
      "Episode 103, Total Reward: 78.0\n",
      "Episode 104, Total Reward: 69.0\n",
      "Episode 105, Total Reward: 50.0\n",
      "Episode 106, Total Reward: 18.0\n",
      "Episode 107, Total Reward: 49.0\n",
      "Episode 108, Total Reward: 17.0\n",
      "Episode 109, Total Reward: 16.0\n",
      "Episode 110, Total Reward: 104.0\n",
      "Episode 111, Total Reward: 40.0\n",
      "Episode 112, Total Reward: 168.0\n",
      "Episode 113, Total Reward: 80.0\n",
      "Episode 114, Total Reward: 64.0\n",
      "Episode 115, Total Reward: 38.0\n",
      "Episode 116, Total Reward: 41.0\n",
      "Episode 117, Total Reward: 220.0\n",
      "Episode 118, Total Reward: 220.0\n",
      "Episode 119, Total Reward: 52.0\n",
      "Episode 120, Total Reward: 28.0\n",
      "Episode 121, Total Reward: 197.0\n",
      "Episode 122, Total Reward: 88.0\n",
      "Episode 123, Total Reward: 116.0\n",
      "Episode 124, Total Reward: 104.0\n",
      "Episode 125, Total Reward: 25.0\n",
      "Episode 126, Total Reward: 39.0\n",
      "Episode 127, Total Reward: 17.0\n",
      "Episode 128, Total Reward: 42.0\n",
      "Episode 129, Total Reward: 17.0\n",
      "Episode 130, Total Reward: 45.0\n",
      "Episode 131, Total Reward: 107.0\n",
      "Episode 132, Total Reward: 54.0\n",
      "Episode 133, Total Reward: 131.0\n",
      "Episode 134, Total Reward: 25.0\n",
      "Episode 135, Total Reward: 149.0\n",
      "Episode 136, Total Reward: 24.0\n",
      "Episode 137, Total Reward: 43.0\n",
      "Episode 138, Total Reward: 14.0\n",
      "Episode 139, Total Reward: 76.0\n",
      "Episode 140, Total Reward: 41.0\n",
      "Episode 141, Total Reward: 51.0\n",
      "Episode 142, Total Reward: 190.0\n",
      "Episode 143, Total Reward: 108.0\n",
      "Episode 144, Total Reward: 131.0\n",
      "Episode 145, Total Reward: 22.0\n",
      "Episode 146, Total Reward: 59.0\n",
      "Episode 147, Total Reward: 138.0\n",
      "Episode 148, Total Reward: 293.0\n",
      "Episode 149, Total Reward: 18.0\n",
      "Episode 150, Total Reward: 30.0\n",
      "Episode 151, Total Reward: 35.0\n",
      "Episode 152, Total Reward: 30.0\n",
      "Episode 153, Total Reward: 136.0\n",
      "Episode 154, Total Reward: 22.0\n",
      "Episode 155, Total Reward: 73.0\n",
      "Episode 156, Total Reward: 21.0\n",
      "Episode 157, Total Reward: 41.0\n",
      "Episode 158, Total Reward: 155.0\n",
      "Episode 159, Total Reward: 109.0\n",
      "Episode 160, Total Reward: 108.0\n",
      "Episode 161, Total Reward: 123.0\n",
      "Episode 162, Total Reward: 41.0\n",
      "Episode 163, Total Reward: 14.0\n",
      "Episode 164, Total Reward: 14.0\n",
      "Episode 165, Total Reward: 53.0\n",
      "Episode 166, Total Reward: 121.0\n",
      "Episode 167, Total Reward: 20.0\n",
      "Episode 168, Total Reward: 15.0\n",
      "Episode 169, Total Reward: 16.0\n",
      "Episode 170, Total Reward: 220.0\n",
      "Episode 171, Total Reward: 36.0\n",
      "Episode 172, Total Reward: 11.0\n",
      "Episode 173, Total Reward: 81.0\n",
      "Episode 174, Total Reward: 19.0\n",
      "Episode 175, Total Reward: 13.0\n",
      "Episode 176, Total Reward: 99.0\n",
      "Episode 177, Total Reward: 30.0\n",
      "Episode 178, Total Reward: 22.0\n",
      "Episode 179, Total Reward: 111.0\n",
      "Episode 180, Total Reward: 84.0\n",
      "Episode 181, Total Reward: 117.0\n",
      "Episode 182, Total Reward: 13.0\n",
      "Episode 183, Total Reward: 38.0\n",
      "Episode 184, Total Reward: 17.0\n",
      "Episode 185, Total Reward: 94.0\n",
      "Episode 186, Total Reward: 111.0\n",
      "Episode 187, Total Reward: 103.0\n",
      "Episode 188, Total Reward: 51.0\n",
      "Episode 189, Total Reward: 226.0\n",
      "Episode 190, Total Reward: 82.0\n",
      "Episode 191, Total Reward: 19.0\n",
      "Episode 192, Total Reward: 15.0\n",
      "Episode 193, Total Reward: 215.0\n",
      "Episode 194, Total Reward: 210.0\n",
      "Episode 195, Total Reward: 33.0\n",
      "Episode 196, Total Reward: 117.0\n",
      "Episode 197, Total Reward: 45.0\n",
      "Episode 198, Total Reward: 15.0\n",
      "Episode 199, Total Reward: 30.0\n",
      "Episode 200, Total Reward: 173.0\n",
      "Episode 201, Total Reward: 146.0\n",
      "Episode 202, Total Reward: 85.0\n",
      "Episode 203, Total Reward: 110.0\n",
      "Episode 204, Total Reward: 16.0\n",
      "Episode 205, Total Reward: 65.0\n",
      "Episode 206, Total Reward: 67.0\n",
      "Episode 207, Total Reward: 153.0\n",
      "Episode 208, Total Reward: 60.0\n",
      "Episode 209, Total Reward: 11.0\n",
      "Episode 210, Total Reward: 154.0\n",
      "Episode 211, Total Reward: 269.0\n",
      "Episode 212, Total Reward: 89.0\n",
      "Episode 213, Total Reward: 167.0\n",
      "Episode 214, Total Reward: 13.0\n",
      "Episode 215, Total Reward: 113.0\n",
      "Episode 216, Total Reward: 180.0\n",
      "Episode 217, Total Reward: 175.0\n",
      "Episode 218, Total Reward: 118.0\n",
      "Episode 219, Total Reward: 206.0\n",
      "Episode 220, Total Reward: 27.0\n",
      "Episode 221, Total Reward: 402.0\n",
      "Episode 222, Total Reward: 211.0\n",
      "Episode 223, Total Reward: 201.0\n",
      "Episode 224, Total Reward: 271.0\n",
      "Episode 225, Total Reward: 75.0\n",
      "Episode 226, Total Reward: 262.0\n",
      "Episode 227, Total Reward: 138.0\n",
      "Episode 228, Total Reward: 121.0\n",
      "Episode 229, Total Reward: 310.0\n",
      "Episode 230, Total Reward: 140.0\n",
      "Episode 231, Total Reward: 279.0\n",
      "Episode 232, Total Reward: 161.0\n",
      "Episode 233, Total Reward: 253.0\n",
      "Episode 234, Total Reward: 14.0\n",
      "Episode 235, Total Reward: 105.0\n",
      "Episode 236, Total Reward: 183.0\n",
      "Episode 237, Total Reward: 217.0\n",
      "Episode 238, Total Reward: 225.0\n",
      "Episode 239, Total Reward: 500.0\n",
      "Episode 240, Total Reward: 21.0\n",
      "Episode 241, Total Reward: 14.0\n",
      "Episode 242, Total Reward: 235.0\n",
      "Episode 243, Total Reward: 308.0\n",
      "Episode 244, Total Reward: 66.0\n",
      "Episode 245, Total Reward: 276.0\n",
      "Episode 246, Total Reward: 285.0\n",
      "Episode 247, Total Reward: 17.0\n",
      "Episode 248, Total Reward: 16.0\n",
      "Episode 249, Total Reward: 238.0\n",
      "Episode 250, Total Reward: 141.0\n",
      "Episode 251, Total Reward: 39.0\n",
      "Episode 252, Total Reward: 106.0\n",
      "Episode 253, Total Reward: 137.0\n",
      "Episode 254, Total Reward: 293.0\n",
      "Episode 255, Total Reward: 107.0\n",
      "Episode 256, Total Reward: 208.0\n",
      "Episode 257, Total Reward: 198.0\n",
      "Episode 258, Total Reward: 177.0\n",
      "Episode 259, Total Reward: 367.0\n",
      "Episode 260, Total Reward: 483.0\n",
      "Episode 261, Total Reward: 70.0\n",
      "Episode 262, Total Reward: 283.0\n",
      "Episode 263, Total Reward: 14.0\n",
      "Episode 264, Total Reward: 500.0\n",
      "Episode 265, Total Reward: 361.0\n",
      "Episode 266, Total Reward: 247.0\n",
      "Episode 267, Total Reward: 27.0\n",
      "Episode 268, Total Reward: 431.0\n",
      "Episode 269, Total Reward: 154.0\n",
      "Episode 270, Total Reward: 105.0\n",
      "Episode 271, Total Reward: 500.0\n",
      "Episode 272, Total Reward: 288.0\n",
      "Episode 273, Total Reward: 359.0\n",
      "Episode 274, Total Reward: 148.0\n",
      "Episode 275, Total Reward: 450.0\n",
      "Episode 276, Total Reward: 500.0\n",
      "Episode 277, Total Reward: 448.0\n",
      "Episode 278, Total Reward: 391.0\n",
      "Episode 279, Total Reward: 130.0\n",
      "Episode 280, Total Reward: 226.0\n",
      "Episode 281, Total Reward: 18.0\n",
      "Episode 282, Total Reward: 97.0\n",
      "Episode 283, Total Reward: 29.0\n",
      "Episode 284, Total Reward: 500.0\n",
      "Episode 285, Total Reward: 445.0\n",
      "Episode 286, Total Reward: 270.0\n",
      "Episode 287, Total Reward: 500.0\n",
      "Episode 288, Total Reward: 104.0\n",
      "Episode 289, Total Reward: 63.0\n",
      "Episode 290, Total Reward: 131.0\n",
      "Episode 291, Total Reward: 321.0\n",
      "Episode 292, Total Reward: 81.0\n",
      "Episode 293, Total Reward: 33.0\n",
      "Episode 294, Total Reward: 17.0\n",
      "Episode 295, Total Reward: 500.0\n",
      "Episode 296, Total Reward: 439.0\n",
      "Episode 297, Total Reward: 209.0\n",
      "Episode 298, Total Reward: 461.0\n",
      "Episode 299, Total Reward: 473.0\n",
      "Episode 300, Total Reward: 500.0\n",
      "Episode 301, Total Reward: 16.0\n",
      "Episode 302, Total Reward: 500.0\n",
      "Episode 303, Total Reward: 429.0\n",
      "Episode 304, Total Reward: 500.0\n",
      "Episode 305, Total Reward: 500.0\n",
      "Episode 306, Total Reward: 95.0\n",
      "Episode 307, Total Reward: 17.0\n",
      "Episode 308, Total Reward: 500.0\n",
      "Episode 309, Total Reward: 172.0\n",
      "Episode 310, Total Reward: 12.0\n",
      "Episode 311, Total Reward: 10.0\n",
      "Episode 312, Total Reward: 190.0\n",
      "Episode 313, Total Reward: 500.0\n",
      "Episode 314, Total Reward: 500.0\n",
      "Episode 315, Total Reward: 98.0\n",
      "Episode 316, Total Reward: 500.0\n",
      "Episode 317, Total Reward: 500.0\n",
      "Episode 318, Total Reward: 377.0\n",
      "Episode 319, Total Reward: 113.0\n",
      "Episode 320, Total Reward: 31.0\n",
      "Episode 321, Total Reward: 151.0\n",
      "Episode 322, Total Reward: 500.0\n",
      "Episode 323, Total Reward: 328.0\n",
      "Episode 324, Total Reward: 46.0\n",
      "Episode 325, Total Reward: 14.0\n",
      "Episode 326, Total Reward: 15.0\n",
      "Episode 327, Total Reward: 451.0\n",
      "Episode 328, Total Reward: 77.0\n",
      "Episode 329, Total Reward: 426.0\n",
      "Episode 330, Total Reward: 500.0\n",
      "Episode 331, Total Reward: 500.0\n",
      "Episode 332, Total Reward: 18.0\n",
      "Episode 333, Total Reward: 500.0\n",
      "Episode 334, Total Reward: 16.0\n",
      "Episode 335, Total Reward: 500.0\n",
      "Episode 336, Total Reward: 50.0\n",
      "Episode 337, Total Reward: 500.0\n",
      "Episode 338, Total Reward: 23.0\n",
      "Episode 339, Total Reward: 500.0\n",
      "Episode 340, Total Reward: 500.0\n",
      "Episode 341, Total Reward: 14.0\n",
      "Episode 342, Total Reward: 500.0\n",
      "Episode 343, Total Reward: 9.0\n",
      "Episode 344, Total Reward: 72.0\n",
      "Episode 345, Total Reward: 500.0\n",
      "Episode 346, Total Reward: 460.0\n",
      "Episode 347, Total Reward: 500.0\n",
      "Episode 348, Total Reward: 437.0\n",
      "Episode 349, Total Reward: 500.0\n",
      "Episode 350, Total Reward: 448.0\n",
      "Episode 351, Total Reward: 500.0\n",
      "Episode 352, Total Reward: 433.0\n",
      "Episode 353, Total Reward: 278.0\n",
      "Episode 354, Total Reward: 500.0\n",
      "Episode 355, Total Reward: 500.0\n",
      "Episode 356, Total Reward: 209.0\n",
      "Episode 357, Total Reward: 500.0\n",
      "Episode 358, Total Reward: 500.0\n",
      "Episode 359, Total Reward: 500.0\n",
      "Episode 360, Total Reward: 500.0\n",
      "Episode 361, Total Reward: 500.0\n",
      "Episode 362, Total Reward: 500.0\n",
      "Episode 363, Total Reward: 385.0\n",
      "Episode 364, Total Reward: 500.0\n",
      "Episode 365, Total Reward: 500.0\n",
      "Episode 366, Total Reward: 500.0\n",
      "Episode 367, Total Reward: 500.0\n",
      "Episode 368, Total Reward: 500.0\n",
      "Episode 369, Total Reward: 500.0\n",
      "Episode 370, Total Reward: 500.0\n",
      "Episode 371, Total Reward: 500.0\n",
      "Episode 372, Total Reward: 500.0\n",
      "Episode 373, Total Reward: 90.0\n",
      "Episode 374, Total Reward: 31.0\n",
      "Episode 375, Total Reward: 128.0\n",
      "Episode 376, Total Reward: 338.0\n",
      "Episode 377, Total Reward: 500.0\n",
      "Episode 378, Total Reward: 14.0\n",
      "Episode 379, Total Reward: 143.0\n",
      "Episode 380, Total Reward: 500.0\n",
      "Episode 381, Total Reward: 500.0\n",
      "Episode 382, Total Reward: 500.0\n",
      "Episode 383, Total Reward: 500.0\n",
      "Episode 384, Total Reward: 500.0\n",
      "Episode 385, Total Reward: 383.0\n",
      "Episode 386, Total Reward: 86.0\n",
      "Episode 387, Total Reward: 295.0\n",
      "Episode 388, Total Reward: 231.0\n",
      "Episode 389, Total Reward: 309.0\n",
      "Episode 390, Total Reward: 396.0\n",
      "Episode 391, Total Reward: 500.0\n",
      "Episode 392, Total Reward: 500.0\n",
      "Episode 393, Total Reward: 500.0\n",
      "Episode 394, Total Reward: 440.0\n",
      "Episode 395, Total Reward: 500.0\n",
      "Episode 396, Total Reward: 500.0\n",
      "Episode 397, Total Reward: 134.0\n",
      "Episode 398, Total Reward: 220.0\n",
      "Episode 399, Total Reward: 125.0\n",
      "Episode 400, Total Reward: 214.0\n",
      "Episode 401, Total Reward: 500.0\n",
      "Episode 402, Total Reward: 500.0\n",
      "Episode 403, Total Reward: 500.0\n",
      "Episode 404, Total Reward: 292.0\n",
      "Episode 405, Total Reward: 60.0\n",
      "Episode 406, Total Reward: 500.0\n",
      "Episode 407, Total Reward: 500.0\n",
      "Episode 408, Total Reward: 299.0\n",
      "Episode 409, Total Reward: 296.0\n",
      "Episode 410, Total Reward: 289.0\n",
      "Episode 411, Total Reward: 500.0\n",
      "Episode 412, Total Reward: 92.0\n",
      "Episode 413, Total Reward: 28.0\n",
      "Episode 414, Total Reward: 82.0\n",
      "Episode 415, Total Reward: 257.0\n",
      "Episode 416, Total Reward: 294.0\n",
      "Episode 417, Total Reward: 341.0\n",
      "Episode 418, Total Reward: 129.0\n",
      "Episode 419, Total Reward: 500.0\n",
      "Episode 420, Total Reward: 13.0\n",
      "Episode 421, Total Reward: 500.0\n",
      "Episode 422, Total Reward: 118.0\n",
      "Episode 423, Total Reward: 500.0\n",
      "Episode 424, Total Reward: 500.0\n",
      "Episode 425, Total Reward: 33.0\n",
      "Episode 426, Total Reward: 106.0\n",
      "Episode 427, Total Reward: 82.0\n",
      "Episode 428, Total Reward: 500.0\n",
      "Episode 429, Total Reward: 32.0\n",
      "Episode 430, Total Reward: 97.0\n",
      "Episode 431, Total Reward: 91.0\n",
      "Episode 432, Total Reward: 32.0\n",
      "Episode 433, Total Reward: 14.0\n",
      "Episode 434, Total Reward: 98.0\n",
      "Episode 435, Total Reward: 133.0\n",
      "Episode 436, Total Reward: 44.0\n",
      "Episode 437, Total Reward: 41.0\n",
      "Episode 438, Total Reward: 97.0\n",
      "Episode 439, Total Reward: 115.0\n",
      "Episode 440, Total Reward: 71.0\n",
      "Episode 441, Total Reward: 119.0\n",
      "Episode 442, Total Reward: 117.0\n",
      "Episode 443, Total Reward: 104.0\n",
      "Episode 444, Total Reward: 500.0\n",
      "Episode 445, Total Reward: 500.0\n",
      "Episode 446, Total Reward: 406.0\n",
      "Episode 447, Total Reward: 106.0\n",
      "Episode 448, Total Reward: 500.0\n",
      "Episode 449, Total Reward: 86.0\n",
      "Episode 450, Total Reward: 61.0\n",
      "Episode 451, Total Reward: 14.0\n",
      "Episode 452, Total Reward: 174.0\n",
      "Episode 453, Total Reward: 94.0\n",
      "Episode 454, Total Reward: 97.0\n",
      "Episode 455, Total Reward: 98.0\n",
      "Episode 456, Total Reward: 103.0\n",
      "Episode 457, Total Reward: 33.0\n",
      "Episode 458, Total Reward: 107.0\n",
      "Episode 459, Total Reward: 44.0\n",
      "Episode 460, Total Reward: 103.0\n",
      "Episode 461, Total Reward: 99.0\n",
      "Episode 462, Total Reward: 102.0\n",
      "Episode 463, Total Reward: 22.0\n",
      "Episode 464, Total Reward: 16.0\n",
      "Episode 465, Total Reward: 176.0\n",
      "Episode 466, Total Reward: 187.0\n",
      "Episode 467, Total Reward: 107.0\n",
      "Episode 468, Total Reward: 92.0\n",
      "Episode 469, Total Reward: 218.0\n",
      "Episode 470, Total Reward: 80.0\n",
      "Episode 471, Total Reward: 297.0\n",
      "Episode 472, Total Reward: 116.0\n",
      "Episode 473, Total Reward: 316.0\n",
      "Episode 474, Total Reward: 430.0\n",
      "Episode 475, Total Reward: 363.0\n",
      "Episode 476, Total Reward: 500.0\n",
      "Episode 477, Total Reward: 17.0\n",
      "Episode 478, Total Reward: 500.0\n",
      "Episode 479, Total Reward: 20.0\n",
      "Episode 480, Total Reward: 500.0\n",
      "Episode 481, Total Reward: 20.0\n",
      "Episode 482, Total Reward: 399.0\n",
      "Episode 483, Total Reward: 276.0\n",
      "Episode 484, Total Reward: 122.0\n",
      "Episode 485, Total Reward: 17.0\n",
      "Episode 486, Total Reward: 490.0\n",
      "Episode 487, Total Reward: 484.0\n",
      "Episode 488, Total Reward: 270.0\n",
      "Episode 489, Total Reward: 229.0\n",
      "Episode 490, Total Reward: 213.0\n",
      "Episode 491, Total Reward: 112.0\n",
      "Episode 492, Total Reward: 500.0\n",
      "Episode 493, Total Reward: 500.0\n",
      "Episode 494, Total Reward: 92.0\n",
      "Episode 495, Total Reward: 145.0\n",
      "Episode 496, Total Reward: 500.0\n",
      "Episode 497, Total Reward: 12.0\n",
      "Episode 498, Total Reward: 216.0\n",
      "Episode 499, Total Reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Custom CartPole Environment\n",
    "class CustomCartPole:\n",
    "    def __init__(self):\n",
    "        # Constants\n",
    "        self.gravity = 9.8\n",
    "        self.mass_cart = 1.0\n",
    "        self.mass_pole = 0.1\n",
    "        self.total_mass = self.mass_cart + self.mass_pole\n",
    "        self.length = 0.5  # Half the length of the pole\n",
    "        self.pole_mass_length = self.mass_pole * self.length\n",
    "        self.force_mag = 10.0\n",
    "        self.tau = 0.02  # Time step (20 ms)\n",
    "        self.theta_threshold_radians = 12 * 2 * np.pi / 360  # 12 degrees\n",
    "        self.x_threshold = 2.4  # Cart position threshold (meters)\n",
    "\n",
    "        # State variables\n",
    "        self.state = None\n",
    "        self.steps_beyond_done = None\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the state to a random small initial value\n",
    "        self.state = np.random.uniform(low=-0.05, high=0.05, size=(4,))\n",
    "        self.steps_beyond_done = None\n",
    "        return np.array(self.state, dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        # Get the current state\n",
    "        x, x_dot, theta, theta_dot = self.state\n",
    "\n",
    "        # Force applied based on action (0: left, 1: right)\n",
    "        force = self.force_mag if action == 1 else -self.force_mag\n",
    "\n",
    "        # Dynamics equations\n",
    "        costheta = np.cos(theta)\n",
    "        sintheta = np.sin(theta)\n",
    "        temp = (force + self.pole_mass_length * theta_dot**2 * sintheta) / self.total_mass\n",
    "        theta_acc = (self.gravity * sintheta - costheta * temp) / \\\n",
    "                    (self.length * (4.0/3.0 - self.mass_pole * costheta**2 / self.total_mass))\n",
    "        x_acc = temp - self.pole_mass_length * theta_acc * costheta / self.total_mass\n",
    "\n",
    "        # Update the state using Euler's method\n",
    "        x = x + self.tau * x_dot\n",
    "        x_dot = x_dot + self.tau * x_acc\n",
    "        theta = theta + self.tau * theta_dot\n",
    "        theta_dot = theta_dot + self.tau * theta_acc\n",
    "        self.state = (x, x_dot, theta, theta_dot)\n",
    "\n",
    "        # Check if the episode is done\n",
    "        done = bool(\n",
    "            x < -self.x_threshold\n",
    "            or x > self.x_threshold\n",
    "            or theta < -self.theta_threshold_radians\n",
    "            or theta > self.theta_threshold_radians\n",
    "        )\n",
    "\n",
    "        # Compute the reward\n",
    "        if not done:\n",
    "            reward = 1.0\n",
    "        elif self.steps_beyond_done is None:\n",
    "            self.steps_beyond_done = 0\n",
    "            reward = 1.0\n",
    "        else:\n",
    "            self.steps_beyond_done += 1\n",
    "            reward = 0.0\n",
    "\n",
    "        return np.array(self.state, dtype=np.float32), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        x, _, theta, _ = self.state\n",
    "        print(f\"Cart Position: {x:.2f}, Pole Angle: {theta:.2f}\")\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "# Q-Network for DQN\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "# DQN Agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.q_network = QNetwork(state_dim, action_dim)\n",
    "        self.target_network = QNetwork(state_dim, action_dim)\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=1e-3)\n",
    "        self.replay_buffer = []\n",
    "        self.buffer_capacity = 10000\n",
    "        self.batch_size = 64\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.01\n",
    "\n",
    "    def act(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randint(0, self.action_dim - 1)\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            return torch.argmax(self.q_network(state_tensor)).item()\n",
    "\n",
    "    def store_transition(self, transition):\n",
    "        if len(self.replay_buffer) >= self.buffer_capacity:\n",
    "            self.replay_buffer.pop(0)\n",
    "        self.replay_buffer.append(transition)\n",
    "\n",
    "    def sample_batch(self):\n",
    "        indices = np.random.choice(len(self.replay_buffer), self.batch_size)\n",
    "        batch = [self.replay_buffer[idx] for idx in indices]\n",
    "        return batch\n",
    "\n",
    "    def learn(self):\n",
    "        if len(self.replay_buffer) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        batch = self.sample_batch()\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        states = torch.FloatTensor(states)\n",
    "        actions = torch.LongTensor(actions)\n",
    "        rewards = torch.FloatTensor(rewards)\n",
    "        next_states = torch.FloatTensor(next_states)\n",
    "        dones = torch.FloatTensor(dones)\n",
    "\n",
    "        q_values = self.q_network(states).gather(1, actions.unsqueeze(1)).squeeze()\n",
    "        with torch.no_grad():\n",
    "            max_next_q_values = self.target_network(next_states).max(1)[0]\n",
    "            target_q_values = rewards + self.gamma * max_next_q_values * (1 - dones)\n",
    "\n",
    "        loss = nn.MSELoss()(q_values, target_q_values)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "env = CustomCartPole()\n",
    "state_dim = 4\n",
    "action_dim = 2\n",
    "agent = DQNAgent(state_dim, action_dim)\n",
    "\n",
    "num_episodes = 500\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "\n",
    "    for t in range(500):\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.store_transition((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "        agent.learn()\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    agent.update_target_network()\n",
    "    agent.epsilon = max(agent.epsilon_min, agent.epsilon * agent.epsilon_decay)\n",
    "    print(f\"Episode {episode}, Total Reward: {total_reward}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
